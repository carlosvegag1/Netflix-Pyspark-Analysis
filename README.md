# ğŸ“º AnÃ¡lisis de Contenido de Netflix con PySpark

<p align="center">
<a href="https://github.com/carlosvegag1/Netflix-Data-Cleaning"><img src="https://i.imgur.com/rekbD3q.png" width="80%"></a>
</p>

## ğŸ¬ Explorando el CatÃ¡logo de Netflix con Big Data

Este proyecto se centra en la limpieza y anÃ¡lisis del catÃ¡logo de Netflix utilizando **PySpark**, una poderosa herramienta de procesamiento distribuido. A lo largo del estudio, se implementan diversas tÃ©cnicas de limpieza de datos, normalizaciÃ³n y transformaciÃ³n para obtener informaciÃ³n estructurada y precisa sobre el contenido disponible en la plataforma.

## ğŸ“Œ Contenido del Proyecto

Este repositorio contiene un anÃ¡lisis detallado con PySpark, incluyendo:

âœ… **Limpieza avanzada de datos con regex y filtrado de valores anÃ³malos.**  
âœ… **NormalizaciÃ³n de duraciones y categorÃ­as (Movies vs. TV Shows).**  
âœ… **OptimizaciÃ³n de consultas con SparkSQL y uso eficiente de DataFrames.**  
âœ… **Uso de Web Scraping para obtener fechas de estreno reales desde IMDb.**  
âœ… **ExportaciÃ³n del dataset final en formato Parquet para optimizaciÃ³n.**  

Se han utilizado fragmentos de cÃ³digo clave para demostrar la eficiencia y robustez del procesamiento con PySpark.

---
## Fragmentos Destacados del CÃ³digo

### ğŸ“… Web Scraping para Obtener Fechas de Estreno Reales desde IMDb
```python
import requests
from bs4 import BeautifulSoup

def obtener_fecha_estreno(url):
    response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        fecha_span = soup.find_all("span", class_="ipc-metadata-list-item__list-content-item")
        if fecha_span:
            return fecha_span[0].text.strip()
    return None
```
ğŸ”¹Este fragmento permite extraer automÃ¡ticamente fechas de estreno reales de IMDb, enriqueciendo el dataset mÃ¡s allÃ¡ de los datos originales.

### ğŸ­ DiferenciaciÃ³n entre PelÃ­culas y Series con Expresiones Regulares
```python
from pyspark.sql.functions import regexp_extract, when

regexMin = r"(\d+)\s+min$"
regexSeasons = r"(\d+)\s+Seasons?$"

dfLimpio = dfLimpio.withColumn(
    "duracionMin",
    when(dfLimpio.duracion.rlike(regexMin), regexp_extract(dfLimpio.duracion, regexMin, 1).cast("int"))
).withColumn(
    "numTemporadas",
    when(dfLimpio.duracion.rlike(regexSeasons), regexp_extract(dfLimpio.duracion, regexSeasons, 1).cast("int"))
)
```
ğŸ”¹ Esto permite separar de forma inteligente la duraciÃ³n en minutos (para pelÃ­culas) y el nÃºmero de temporadas (para series), mejorando la usabilidad de los datos.

### â³ ComparaciÃ³n de DuraciÃ³n Media entre Producciones Individuales y Coproducciones
```python
from pyspark.sql.functions import split, explode, avg, round

# Explodemos la columna 'pais' para obtener cada paÃ­s individualmente
df_paisIndividual = dfLimpio.withColumn("paisIndividual", explode(split(dfLimpio.pais, ", ")))

# CÃ¡lculo de la duraciÃ³n media por paÃ­s y por coproducciÃ³n
mediaDuracionPorPais = dfLimpio.groupBy("pais").agg(round(avg("duracionMin"), 2).alias("mediaDuracion"))
mediaDuracionSiParticipa = df_paisIndividual.groupBy("paisIndividual").agg(round(avg("duracionMin"), 2).alias("mediaDuracionSiParticipa"))

# ComparaciÃ³n de duraciÃ³n entre producciones individuales y coproducciones
comparacionDuracion = mediaDuracionPorPais.alias("general").join(
    mediaDuracionSiParticipa.alias("participa"),
    mediaDuracionPorPais.pais == mediaDuracionSiParticipa.paisIndividual,
    "inner"
).select(
    col("general.pais").alias("PaÃ­s"),
    col("general.mediaDuracion").alias("DuraciÃ³n Media (ProducciÃ³n Nacional)"),
    col("participa.mediaDuracionSiParticipa").alias("DuraciÃ³n Media (Si Participa)")
)

comparacionDuracion.show(truncate=False)
```
---

##  InstalaciÃ³n y Uso

### 1ï¸ Clonar el Repositorio
```bash
git clone https://github.com/carlosvegag1/netflix-data-cleaning.git
cd netflix-data-cleaning
```
### 2ï¸ Crear un Entorno Virtual e Instalar Dependencias
```bash
python -m venv env
source env/bin/activate  # (Windows: env\Scripts\activate)
pip install -r requirements.txt
```
### 3ï¸ Ejecutar el Notebook
```bash
Abre Jupyter Notebook y ejecuta netflix_data_cleaning.ipynb
jupyter notebook
```

##  Otras formas de visualizar el anÃ¡lisis  
Si prefieres explorar el anÃ¡lisis sin necesidad de ejecutar cÃ³digo, puedes acceder aquÃ­:  

ğŸ“„ **VersiÃ³n en HTML**  
ğŸ”— **[Netflix-Data-Cleaning.html](https://carlosvegag1.github.io/netflix-data-cleaning/netflix_analysis.html)**  

ğŸ“„ **VersiÃ³n en PDF**  
ğŸ”— **[Netflix-Data-Cleaning.pdf](https://github.com/carlosvegag1/netflix-data-cleaning/blob/main/docs/netflix_analysis.pdf)**

---

## ğŸ“¥ Origen de los Datos
Los datos analizados en este proyecto provienen del repositorio de **DataCamp** sobre limpieza de datos en PySpark. Se han descargado, procesado y enriquecido con informaciÃ³n adicional obtenida mediante *web scraping* de IMDb.

ğŸ”— **[Dataset Original en DataCamp](https://github.com/datacamp/data-cleaning-with-pyspark-live-training)**

Para mÃ¡s informaciÃ³n sobre el dataset y otros proyectos de limpieza de datos, visita la fuente oficial de DataCamp.

---

### ğŸ¤ Compalte
Este proyecto ha sido desarrollado como parte de mi formaciÃ³n en **Ciencia de Datos** con PySpark. Si tienes sugerencias o quieres contribuir, Â¡serÃ¡s bienvenido!

**â­ Si te resulta Ãºtil, no olvides darle una estrella al repositorio.**

### ğŸ“¬ Contacto
ğŸ“Œ **LinkedIn:** [Carlos Vega GonzÃ¡lez](https://www.linkedin.com/in/carlos-vega-gonzalez/)  
ğŸ“§ **Email:** carlosvegagonzalez1@gmail.com  
